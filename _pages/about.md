---
layout: about
title: About
permalink: /
subtitle: Hi, I am Yuxia Wang (王宇侠 in Chinese).

profile:
  align: right
  image: yuxia_img.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>NLP Department</p>
    <p>MBZUAI, 1B, Block C</p>
    <p>Masdar City, Abu Dhabi, UAE</p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am currently a postdoctoral researcher at <a href="https://mbzuai.ac.ae/research/department/natural-language-processing-department/">MBZUAI NLP department</a>, working with <a href="https://mbzuai.ac.ae/study/faculty/preslav-nakov/">Prof. Preslav Nakov</a>. I will be joining INSAIT in Sofia as a tenure-track Assistant Professor starting in Fall 2025. Prior to this, I completed my PhD at The University of Melbourne in January 2023, under the guidance of <a href="https://eltimster.github.io/www/" target="_blank">Prof. Tim Baldwin</a> and <a href="https://www.rmit.edu.au/profiles/v/karin-verspoor" target="_blank">Prof. Karin Verspoor</a>. I earned both my Bachelor’s (2016) and Master’s (2018) degrees from the Beijing Institute of Technology.

My research interests lie in natural language processing and artificial intelligence, with a particular goal to advance safe, factual, and empathetic human-AI interactions. My current work mainly focuses on LLM/LRM optimization in safety, factuality and empathy, low-resource language model development, and machine-generated content detection. I have published papers in top-tier NLP conferences and journals such as ACL, TACL, EMNLP, NAACL and so on.